{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/Y1CTNy9.jpeg\">\n\n# <b><span style='color:#F1A424'>|</span> DAIGT: <span style='color:#F1A424'>Text Classification</span><span style='color:#ABABAB'> [Train]</span></b> \n\n***\n\n\n### <b><span style='color:#F1A424'>Table of Contents</span></b> <a class='anchor' id='top'></a>\n<div style=\" background-color:#3b3745; padding: 13px 13px; border-radius: 8px; color: white\">\n<li> <a href=\"#introduction\">Introduction</a></li>\n<li> <a href=\"#install_libraries\">Install libraries</a></li>\n<li><a href=\"#import_libraries\">Import Libraries</a></li>\n<li><a href=\"#configuration\">Configuration</a></li>\n<li><a href=\"#utils\">Utils</a></li>\n<li><a href=\"#load_data\">Load Data</a></li>\n<li><a href=\"#validation\">Validation</a></li>\n<li><a href=\"#dataset\">Dataset</a></li>\n<li><a href=\"#model\">Model</a></li>\n<li><a href=\"#loss\">Loss Function</a></li>\n<li><a href=\"#functions\">Train and Validation Functions</a></li>\n<li><a href=\"#train_loop\">Train Loop</a></li>\n<li><a href=\"#train\">Train</a></li>\n<li><a href=\"#evaluate\">Evaluate</a></li>\n</div>\n\n\n# <b><span style='color:#F1A424'>|</span> Introduction</b><a class='anchor' id='introduction'></a> [↑](#top) \n\n***\n\n### <b><span style='color:#F1A424'>Useful References</span></b>\n\n- [Deberta v3 Hugging Face](https://huggingface.co/microsoft/deberta-v3-base)\n- [Deberta paper](https://arxiv.org/abs/2006.03654)","metadata":{"papermill":{"duration":0.012455,"end_time":"2022-08-31T07:01:57.321119","exception":false,"start_time":"2022-08-31T07:01:57.308664","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Import Libraries</b><a class='anchor' id='import_libraries'></a> [↑](#top) \n\n***\n\nImport all the required libraries for this notebook.","metadata":{}},{"cell_type":"code","source":"import ast\nimport copy\nimport gc\nimport itertools\nimport joblib\nimport json\nimport math\nimport matplotlib.pyplot as plt\nimport multiprocessing\nimport numpy as np\nimport os\nimport pandas as pd\nimport pickle\nimport random\nimport re\nimport scipy as sp\nimport string\nimport sys\nimport time\nimport warnings\nimport wandb\n\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm.auto import tqdm\n\n# ======= OPTIONS =========\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Current device is: {device}\")\nwarnings.filterwarnings(\"ignore\")\n!mkdir output","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-11-01T04:26:31.157691Z","iopub.execute_input":"2023-11-01T04:26:31.158305Z","iopub.status.idle":"2023-11-01T04:26:36.663839Z","shell.execute_reply.started":"2023-11-01T04:26:31.158272Z","shell.execute_reply":"2023-11-01T04:26:36.662573Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Current device is: cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### <b><span style='color:#F1A424'>Tokenizers and transformers</span></b>","metadata":{}},{"cell_type":"code","source":"import tokenizers\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")","metadata":{"_kg_hide-input":true,"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-01T04:27:06.038825Z","iopub.execute_input":"2023-11-01T04:27:06.039675Z","iopub.status.idle":"2023-11-01T04:27:13.956064Z","shell.execute_reply.started":"2023-11-01T04:27:06.039640Z","shell.execute_reply":"2023-11-01T04:27:13.955050Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"env: TOKENIZERS_PARALLELISM=true\ntokenizers.__version__: 0.13.3\ntransformers.__version__: 4.33.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Configuration</b><a class='anchor' id='configuration'></a> [↑](#top) \n\n***\n\nCentral repository for this notebook's hyperparameters.","metadata":{"papermill":{"duration":0.006569,"end_time":"2022-08-31T07:01:57.395826","exception":false,"start_time":"2022-08-31T07:01:57.389257","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class config:\n    APEX = True # Automatic Precision Enabled\n    BATCH_SCHEDULER = True\n    BATCH_SIZE_TRAIN = 32\n    BATCH_SIZE_VALID = 16\n    BETAS = (0.9, 0.999)\n    DEBUG = False\n    DECODER_LR = 2e-5\n    ENCODER_LR = 2e-5\n    EPOCHS = 3\n    EPS = 1e-6\n    FOLDS = 4\n    GRADIENT_ACCUMULATION_STEPS = 1\n    GRADIENT_CHECKPOINTING = True\n    MAX_GRAD_NORM=1000\n    MAX_LEN = 512\n    MIN_LR = 1e-6\n    MODEL = \"microsoft/deberta-v3-base\"\n    NUM_CYCLES = 0.5\n    NUM_WARMUP_STEPS = 0\n    NUM_WORKERS = multiprocessing.cpu_count()\n    PRINT_FREQ = 20\n    SCHEDULER = 'cosine' # ['linear', 'cosine']\n    SEED = 27\n    TRAIN = True\n    TRAIN_FOLDS = [0, 1, 2, 3]\n    WANDB = False\n    WEIGHT_DECAY = 0.01\n\n    \nclass paths:\n    OUTPUT_DIR = \"/kaggle/working/output\"\n    EXTERNAL_DATA = \"/kaggle/input/daigt-external-dataset/daigt_external_dataset.csv\"\n    TRAIN_PROMPTS = \"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\"\n    TRAIN_ESSAYS = \"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\"\n    TEST_ESSAYS = \"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\"\n    \n\nif config.DEBUG:\n    config.EPOCHS = 2\n    config.TRAIN_FOLDS = [0]","metadata":{"papermill":{"duration":0.015868,"end_time":"2022-08-31T07:01:57.417077","exception":false,"start_time":"2022-08-31T07:01:57.401209","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:13.957864Z","iopub.execute_input":"2023-11-01T04:27:13.958602Z","iopub.status.idle":"2023-11-01T04:27:13.966974Z","shell.execute_reply.started":"2023-11-01T04:27:13.958565Z","shell.execute_reply":"2023-11-01T04:27:13.966012Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Utils</b><a class='anchor' id='utils'></a> [↑](#top) \n\n***\n\nUtility functions used throughout the notebook.","metadata":{"papermill":{"duration":0.007998,"end_time":"2022-08-31T07:03:04.079768","exception":false,"start_time":"2022-08-31T07:03:04.07177","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_config_dict(config):\n    \"\"\"\n    Return the config, which is originally a class, as a Python dictionary.\n    \"\"\"\n    config_dict = dict((key, value) for key, value in config.__dict__.items() \n    if not callable(value) and not key.startswith('__'))\n    return config_dict\n\n\ndef get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n         'lr': encoder_lr, 'weight_decay': weight_decay},\n        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n         'lr': encoder_lr, 'weight_decay': 0.0},\n        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n         'lr': decoder_lr, 'weight_decay': 0.0}\n    ]\n    return optimizer_parameters\n\n\ndef get_logger(filename=paths.OUTPUT_DIR):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\n\ndef get_scheduler(cfg, optimizer, num_train_steps):\n    if cfg.SCHEDULER == 'linear':\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS,\n            num_training_steps=num_train_steps\n        )\n    elif cfg.SCHEDULER == 'cosine':\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer, num_warmup_steps=cfg.NUM_WARMUP_STEPS,\n            num_training_steps=num_train_steps, num_cycles=cfg.NUM_CYCLES\n        )\n    return scheduler\n    \n\ndef get_score(y_trues, y_preds):\n    score = roc_auc_score(y_trues, y_preds)\n    return score\n\n\ndef seed_everything(seed=20):\n    \"\"\"Seed everything to ensure reproducibility\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \n\ndef sep():\n    print(\"-\"*100)\n    \n    \ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))  \n    \nLOGGER = get_logger()\nseed_everything(seed=config.SEED)","metadata":{"papermill":{"duration":0.024132,"end_time":"2022-08-31T07:03:04.111108","exception":false,"start_time":"2022-08-31T07:03:04.086976","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:16.383516Z","iopub.execute_input":"2023-11-01T04:27:16.384263Z","iopub.status.idle":"2023-11-01T04:27:16.404066Z","shell.execute_reply.started":"2023-11-01T04:27:16.384230Z","shell.execute_reply":"2023-11-01T04:27:16.403205Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Weights and Biases 🐝</b><a class='anchor' id='wandb'></a> [↑](#top) \n\n***\n\nWeights and Biases for tracking experiments.","metadata":{}},{"cell_type":"code","source":"import wandb\n\nnotes = \"\"\n\nif config.WANDB:\n    try:\n        from kaggle_secrets import UserSecretsClient\n        user_secrets = UserSecretsClient()\n        secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n        wandb.login(key=secret_value_0)\n        anony = None\n    except:\n        anony = \"must\"\n        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n\n    run = wandb.init(project='CommonLit', \n                     name=\"test_1\",\n                     config=get_config_dict(config),\n                     group=\"anti_overfit\",\n                     job_type=\"train\",\n                     notes=notes,\n                     anonymous=anony)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:27:28.317826Z","iopub.execute_input":"2023-11-01T04:27:28.318634Z","iopub.status.idle":"2023-11-01T04:27:28.324425Z","shell.execute_reply.started":"2023-11-01T04:27:28.318601Z","shell.execute_reply":"2023-11-01T04:27:28.323472Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Load Data</b><a class='anchor' id='load_data'></a> [↑](#top) \n\n***\n\nLoad data.","metadata":{"papermill":{"duration":0.012589,"end_time":"2022-08-31T07:03:04.13341","exception":false,"start_time":"2022-08-31T07:03:04.120821","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df = pd.read_csv(paths.TRAIN_ESSAYS, sep=',')\nexternal_df = pd.read_csv(paths.EXTERNAL_DATA, sep=',')\ntrain_prompts = pd.read_csv(paths.TRAIN_PROMPTS, sep=',')\nprint(f\"Train essays dataframe has shape: {train_df.shape}\"), sep()\nprint(f\"External essays dataframe has shape: {external_df.shape}\"), sep()\nprint(f\"Train prompts dataframe has shape: {train_prompts.shape}\"), sep()\ndisplay(train_df.head())\ndisplay(external_df.head())\ndisplay(train_prompts.head())","metadata":{"papermill":{"duration":0.242687,"end_time":"2022-08-31T07:03:04.383434","exception":false,"start_time":"2022-08-31T07:03:04.140747","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:30.215640Z","iopub.execute_input":"2023-11-01T04:27:30.216565Z","iopub.status.idle":"2023-11-01T04:27:30.607169Z","shell.execute_reply.started":"2023-11-01T04:27:30.216531Z","shell.execute_reply":"2023-11-01T04:27:30.606208Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Train essays dataframe has shape: (1378, 4)\n----------------------------------------------------------------------------------------------------\nExternal essays dataframe has shape: (2421, 4)\n----------------------------------------------------------------------------------------------------\nTrain prompts dataframe has shape: (2, 4)\n----------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"         id  prompt_id                                               text  generated\n0  0059830c          0  Cars. Cars have been around since they became ...          0\n1  005db917          0  Transportation is a large necessity in most co...          0\n2  008f63e3          0  \"America's love affair with it's vehicles seem...          0\n3  00940276          0  How often do you ride in a car? Do you drive a...          0\n4  00c39458          0  Cars are a wonderful thing. They are perhaps o...          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>0</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>0</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>0</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>0</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>0</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"             id                                               text                                       instructions                                        source_text\n0  6060D28C05B6  Some schools in United States ofter classes fr...  \\nTask: Write a persuasive essay on whether or...  \\nWhen considering the pros and cons of attend...\n1  60623DB5DE7A  Four-day work week, a remarkable idea to conse...  \\nTask: Research the advantages and disadvanta...  \\nOne of the primary arguments for implementin...\n2  607A39D981DE  Students and their families should consider an...  \\nTask: \\n\\n1. Talk to your parents before tak...  \\nBefore making any decisions about getting in...\n3  60ACDFA1609E  Agree you will never grow if something beyond ...  \\nTask: Write an essay discussing the benefits...  \\nRalph Waldo Emerson once said, \"Go confident...\n4  60AE13D3F07B  I think our character traits are formed by inf...  \\nTask: Research and discuss how character tra...  \\nHuman character traits are shaped by a wide ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>instructions</th>\n      <th>source_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6060D28C05B6</td>\n      <td>Some schools in United States ofter classes fr...</td>\n      <td>\\nTask: Write a persuasive essay on whether or...</td>\n      <td>\\nWhen considering the pros and cons of attend...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>60623DB5DE7A</td>\n      <td>Four-day work week, a remarkable idea to conse...</td>\n      <td>\\nTask: Research the advantages and disadvanta...</td>\n      <td>\\nOne of the primary arguments for implementin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>607A39D981DE</td>\n      <td>Students and their families should consider an...</td>\n      <td>\\nTask: \\n\\n1. Talk to your parents before tak...</td>\n      <td>\\nBefore making any decisions about getting in...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>60ACDFA1609E</td>\n      <td>Agree you will never grow if something beyond ...</td>\n      <td>\\nTask: Write an essay discussing the benefits...</td>\n      <td>\\nRalph Waldo Emerson once said, \"Go confident...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60AE13D3F07B</td>\n      <td>I think our character traits are formed by inf...</td>\n      <td>\\nTask: Research and discuss how character tra...</td>\n      <td>\\nHuman character traits are shaped by a wide ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   prompt_id                       prompt_name                                       instructions                                        source_text\n0          0                   Car-free cities  Write an explanatory essay to inform fellow ci...  # In German Suburb, Life Goes On Without Cars ...\n1          1  Does the electoral college work?  Write a letter to your state senator in which ...  # What Is the Electoral College? by the Office...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_name</th>\n      <th>instructions</th>\n      <th>source_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Car-free cities</td>\n      <td>Write an explanatory essay to inform fellow ci...</td>\n      <td># In German Suburb, Life Goes On Without Cars ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Does the electoral college work?</td>\n      <td>Write a letter to your state senator in which ...</td>\n      <td># What Is the Electoral College? by the Office...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### <b><span style='color:#F1A424'>Add External Data</span></b>","metadata":{}},{"cell_type":"code","source":"external_df = external_df[[\"id\", \"source_text\"]]\nexternal_df.columns = [\"id\", \"text\"]\nexternal_df['text'] = external_df['text'].str.replace('\\n', '')\nexternal_df[\"generated\"] = 1\ntrain_df.drop(columns=[\"prompt_id\"],inplace=True)\ntrain_df = pd.concat([train_df, external_df])\ntrain_df.reset_index(inplace=True, drop=True)\nprint(f\"Train dataframe has shape: {train_df.shape}\"), sep()\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:27:33.501734Z","iopub.execute_input":"2023-11-01T04:27:33.502084Z","iopub.status.idle":"2023-11-01T04:27:33.535442Z","shell.execute_reply.started":"2023-11-01T04:27:33.502056Z","shell.execute_reply":"2023-11-01T04:27:33.534454Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Train dataframe has shape: (3799, 3)\n----------------------------------------------------------------------------------------------------\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"         id                                               text  generated\n0  0059830c  Cars. Cars have been around since they became ...          0\n1  005db917  Transportation is a large necessity in most co...          0\n2  008f63e3  \"America's love affair with it's vehicles seem...          0\n3  00940276  How often do you ride in a car? Do you drive a...          0\n4  00c39458  Cars are a wonderful thing. They are perhaps o...          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Validation</b><a class='anchor' id='validation'></a> [↑](#top) \n\n***","metadata":{"papermill":{"duration":0.008293,"end_time":"2022-08-31T07:03:04.40102","exception":false,"start_time":"2022-08-31T07:03:04.392727","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=5)\nX = train_df.loc[:, train_df.columns != \"generated\"]\ny = train_df.loc[:, train_df.columns == \"generated\"]\n\nfor i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n    train_df.loc[valid_index, \"fold\"] = i\n    \nprint(train_df.groupby(\"fold\")[\"generated\"].value_counts())\ntrain_df.head()","metadata":{"papermill":{"duration":0.148391,"end_time":"2022-08-31T07:03:04.558882","exception":false,"start_time":"2022-08-31T07:03:04.410491","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:34.533302Z","iopub.execute_input":"2023-11-01T04:27:34.533661Z","iopub.status.idle":"2023-11-01T04:27:34.567588Z","shell.execute_reply.started":"2023-11-01T04:27:34.533632Z","shell.execute_reply":"2023-11-01T04:27:34.566525Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"fold  generated\n0.0   1            485\n      0            275\n1.0   1            485\n      0            275\n2.0   1            485\n      0            275\n3.0   1            485\n      0            275\n4.0   1            484\n      0            275\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"         id                                               text  generated  fold\n0  0059830c  Cars. Cars have been around since they became ...          0   0.0\n1  005db917  Transportation is a large necessity in most co...          0   0.0\n2  008f63e3  \"America's love affair with it's vehicles seem...          0   0.0\n3  00940276  How often do you ride in a car? Do you drive a...          0   0.0\n4  00c39458  Cars are a wonderful thing. They are perhaps o...          0   0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>generated</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenizer <a class='anchor' id='tokenizer'> [↑](#top)","metadata":{"papermill":{"duration":0.007561,"end_time":"2022-08-31T07:03:04.604916","exception":false,"start_time":"2022-08-31T07:03:04.597355","status":"completed"},"tags":[]}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.MODEL)\ntokenizer.save_pretrained(paths.OUTPUT_DIR + '/tokenizer/')\nprint(tokenizer)","metadata":{"papermill":{"duration":7.351568,"end_time":"2022-08-31T07:03:11.964298","exception":false,"start_time":"2022-08-31T07:03:04.61273","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:36.387134Z","iopub.execute_input":"2023-11-01T04:27:36.387474Z","iopub.status.idle":"2023-11-01T04:27:39.787388Z","shell.execute_reply.started":"2023-11-01T04:27:36.387449Z","shell.execute_reply":"2023-11-01T04:27:39.786384Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34173343fa2943b4930d01320bf1fe0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a3ad592b3a545c89eb51e63016aa1c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5bcb6ec0a244224998f04aeb19a970f"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"DebertaV2TokenizerFast(name_or_path='microsoft/deberta-v3-base', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Dataset</b><a class='anchor' id='dataset'></a> [↑](#top) \n\n***\n\n    \nWe need to get the `max_len` from our `tokenizer`. We create a `tqdm` iterator and for each text we extract the tokenized length. Then we get the maximum value and we add 3 for the special tokens `CLS`, `SEP`, `SEP`.\n\n- [Hugging Face Padding and Truncation](https://huggingface.co/docs/transformers/pad_truncation): check truncation to `max_length` or `True` (batch max length).","metadata":{"papermill":{"duration":0.008127,"end_time":"2022-08-31T07:03:11.985369","exception":false,"start_time":"2022-08-31T07:03:11.977242","status":"completed"},"tags":[]}},{"cell_type":"code","source":"lengths = []\ntqdm_loader = tqdm(train_df['text'].fillna(\"\").values, total=len(train_df))\nfor text in tqdm_loader:\n    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n    lengths.append(length)\n    \n# config.MAX_LEN = max(lengths) + 3 # cls & sep & sep\nLOGGER.info(f\"max_len: {config.MAX_LEN}\")\n_ = plt.hist(lengths, bins=25)","metadata":{"papermill":{"duration":5.893032,"end_time":"2022-08-31T07:03:17.886504","exception":false,"start_time":"2022-08-31T07:03:11.993472","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:40.194483Z","iopub.execute_input":"2023-11-01T04:27:40.194876Z","iopub.status.idle":"2023-11-01T04:27:45.386913Z","shell.execute_reply.started":"2023-11-01T04:27:40.194843Z","shell.execute_reply":"2023-11-01T04:27:45.385901Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3799 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db6b801562a4784abf26ad4cd462c3c"}},"metadata":{}},{"name":"stderr","text":"max_len: 512\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"def prepare_input(cfg, text, tokenizer):\n    \"\"\"\n    This function tokenizes the input text with the configured padding and truncation. Then,\n    returns the input dictionary, which contains the following keys: \"input_ids\",\n    \"token_type_ids\" and \"attention_mask\". Each value is a torch.tensor.\n    :param cfg: configuration class with a TOKENIZER attribute.\n    :param text: a numpy array where each value is a text as string.\n    :return inputs: python dictionary where values are torch tensors.\n    \"\"\"\n    inputs = tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        max_length=cfg.MAX_LEN,\n        padding='max_length', # TODO: check padding to max sequence in batch\n        truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long) # TODO: check dtypes\n    return inputs\n\n\ndef collate(inputs):\n    \"\"\"\n    It truncates the inputs to the maximum sequence length in the batch. \n    \"\"\"\n    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max()) # Get batch's max sequence length\n    for k, v in inputs.items():\n        inputs[k] = inputs[k][:,:mask_len]\n    return inputs\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, cfg, df, tokenizer):\n        self.cfg = cfg\n        self.texts = df['text'].values\n        self.labels = df['generated'].values\n        self.tokenizer = tokenizer\n        self.text_ids = df['id'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        output = {}\n        output[\"inputs\"] = prepare_input(self.cfg, self.texts[item], self.tokenizer)\n        output[\"labels\"] = torch.tensor(self.labels[item], dtype=torch.float) # TODO: check dtypes\n        output[\"ids\"] = self.text_ids[item]\n        return output","metadata":{"papermill":{"duration":0.020447,"end_time":"2022-08-31T07:03:17.916566","exception":false,"start_time":"2022-08-31T07:03:17.896119","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:45.389030Z","iopub.execute_input":"2023-11-01T04:27:45.389513Z","iopub.status.idle":"2023-11-01T04:27:45.401644Z","shell.execute_reply.started":"2023-11-01T04:27:45.389471Z","shell.execute_reply":"2023-11-01T04:27:45.400650Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"One sample from the dataset should look as following:\n```python\n{\n\t'inputs': {\n\t\t'input_ids': tensor([1, 279, 883, ..., 0, 0]),\n\t\t'token_type_ids': tensor([0, 0, 0, ..., 0, 0]),\n\t\t'attention_mask': tensor([1, 1, 1, ..., 0, 0])\n\t},\n\t'label': tensor([0.0]),\n\t'ids': '000e8c3c7ddb'\n}\n```\nYou can check it by running the cell below.","metadata":{}},{"cell_type":"code","source":"if config.DEBUG:\n    # ======== SPLIT ==========\n    fold = 0\n    train_folds = train_df[train_df['fold'] != fold].reset_index(drop=True)\n    valid_folds = train_df[train_df['fold'] == fold].reset_index(drop=True)\n    valid_labels = valid_folds['generated'].values\n\n    # ======== DATASETS ==========\n    train_dataset = CustomDataset(config, train_folds, tokenizer)\n    valid_dataset = CustomDataset(config, valid_folds, tokenizer)\n\n    # ======== DATALOADERS ==========\n    train_loader = DataLoader(train_dataset,\n                              batch_size=config.BATCH_SIZE_TRAIN, # TODO: split into train and valid\n                              shuffle=True,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=config.BATCH_SIZE_VALID,\n                              shuffle=False,\n                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n\n    # === Let's check one sample ===\n    sample = train_dataset[0]\n    print(f\"Encoding keys: {sample.keys()} \\n\") \n    print(sample)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-11-01T04:27:45.402737Z","iopub.execute_input":"2023-11-01T04:27:45.403028Z","iopub.status.idle":"2023-11-01T04:27:45.425691Z","shell.execute_reply.started":"2023-11-01T04:27:45.402995Z","shell.execute_reply":"2023-11-01T04:27:45.424857Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Model</b><a class='anchor' id='model'></a> [↑](#top) \n\n***","metadata":{"papermill":{"duration":0.008073,"end_time":"2022-08-31T07:03:17.933189","exception":false,"start_time":"2022-08-31T07:03:17.925116","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n    \n\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.dropout = 0.2\n        # Load config by inferencing it from the model name.\n        if config_path is None: \n            self.config = AutoConfig.from_pretrained(cfg.MODEL, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n        # Load config from a file.\n        else:\n            self.config = torch.load(config_path)\n        \n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.MODEL, config=self.config)\n        else:\n            self.model = AutoModel(self.config)\n        \n        if self.cfg.GRADIENT_CHECKPOINTING:\n            self.model.gradient_checkpointing_enable()\n          \n        # Add MeanPooling and Linear head at the end to transform the Model into a RegressionModel\n        self.pool = MeanPooling()\n        self.head = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Dropout(self.dropout),\n            nn.Linear(64, 16),\n            nn.BatchNorm1d(16),\n            nn.ReLU(),\n            nn.Dropout(self.dropout),\n            nn.Linear(16, 1)\n        )\n#         self._init_weights(self.head)\n        \n    def _init_weights(self, module):\n        \"\"\"\n        This method initializes weights for different types of layers. The type of layers \n        supported are nn.Linear, nn.Embedding and nn.LayerNorm.\n        \"\"\"\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        \"\"\"\n        This method makes a forward pass through the model, get the last hidden state (embedding)\n        and pass it through the MeanPooling layer.\n        \"\"\"\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n        return feature\n\n    def forward(self, inputs):\n        \"\"\"\n        This method makes a forward pass through the model, the MeanPooling layer and finally\n        then through the Linear layer to get a regression value.\n        \"\"\"\n        feature = self.feature(inputs)\n        output = self.head(feature)\n        return output","metadata":{"papermill":{"duration":0.033105,"end_time":"2022-08-31T07:03:17.97447","exception":false,"start_time":"2022-08-31T07:03:17.941365","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:45.427455Z","iopub.execute_input":"2023-11-01T04:27:45.427721Z","iopub.status.idle":"2023-11-01T04:27:45.446038Z","shell.execute_reply.started":"2023-11-01T04:27:45.427698Z","shell.execute_reply":"2023-11-01T04:27:45.445248Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train and Validation Functions</b><a class='anchor' id='functions'></a> [↑](#top) \n\n***\n    \n- [torch.cuda.amp.GradScaler](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler): This class helps writing compute efficient training loops, so we dont get OOM errors. Also, one common error in any large deep learning model is the problem of underflowing gradients (i.e. your gradients are too small to take into account). `float16` tensors often don't take into account extremely small variations. To prevent this we can scale our gradients by some factor so that they aren't flushed to zero. Not to be confused with vanishing gradients, this gradients still might contribute to the learning process however are skipped because of computational limits.\n- [torch.autocast](https://pytorch.org/docs/stable/amp.html#torch.autocast)","metadata":{"papermill":{"duration":0.008452,"end_time":"2022-08-31T07:03:18.041557","exception":false,"start_time":"2022-08-31T07:03:18.033105","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    \"\"\"One epoch training pass.\"\"\"\n    model.train() # set model in train mode\n    scaler = torch.cuda.amp.GradScaler(enabled=config.APEX) # Automatic Mixed Precision tries to match each op to its appropriate datatype.\n    losses = AverageMeter() # initiate AverageMeter to track the loss.\n    start = end = time.time() # track the execution time.\n    global_step = 0\n    \n    # ========== ITERATE OVER TRAIN BATCHES ============\n    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n        for step, batch in enumerate(tqdm_train_loader):\n            inputs = batch.pop(\"inputs\")\n            labels = batch.pop(\"labels\")\n            inputs = collate(inputs) # collate inputs\n            for k, v in inputs.items(): # send each tensor value to `device`\n                inputs[k] = v.to(device)\n            labels = labels.to(device) # send labels to `device`\n            batch_size = labels.size(0)\n            with torch.cuda.amp.autocast(enabled=config.APEX):\n                y_preds = model(inputs) # forward propagation pass\n                loss = criterion(y_preds, labels.unsqueeze(1)) # get loss\n            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n            losses.update(loss.item(), batch_size) # update loss function tracking\n            scaler.scale(loss).backward() # backward propagation pass\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n\n            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n                scaler.step(optimizer) # update optimizer parameters\n                scaler.update()\n                optimizer.zero_grad() # zero out the gradients\n                global_step += 1\n                if config.BATCH_SCHEDULER:\n                    scheduler.step() # update learning rate\n            end = time.time() # get finish time\n\n            # ========== LOG INFO ==========\n            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n                print('Epoch: [{0}][{1}/{2}] '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.avg:.4f} '\n                      'Grad: {grad_norm:.4f}  '\n                      'LR: {lr:.8f}  '\n                      .format(epoch+1, step, len(train_loader), \n                              remain=timeSince(start, float(step+1)/len(train_loader)),\n                              loss=losses,\n                              grad_norm=grad_norm,\n                              lr=scheduler.get_lr()[0]))\n            if config.WANDB:\n                wandb.log({f\"[fold_{fold}] train loss\": losses.val,\n                           f\"[fold_{fold}] lr\": scheduler.get_lr()[0]})\n\n    return losses.avg\n\n\ndef valid_epoch(valid_loader, model, criterion, device):\n    model.eval() # set model in evaluation mode\n    losses = AverageMeter() # initiate AverageMeter for tracking the loss.\n    prediction_dict = {}\n    preds = []\n    start = end = time.time() # track the execution time.\n    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n        for step, batch in enumerate(tqdm_valid_loader):\n            inputs = batch.pop(\"inputs\")\n            labels = batch.pop(\"labels\")\n            ids = batch.pop(\"ids\")\n            inputs = collate(inputs) # collate inputs\n            for k, v in inputs.items():\n                inputs[k] = v.to(device) # send inputs to device\n            labels = labels.to(device)\n            batch_size = labels.size(0)\n            with torch.no_grad():\n                y_preds = model(inputs) # forward propagation pass\n                loss = criterion(y_preds, labels.unsqueeze(1)) # get loss\n            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n            losses.update(loss.item(), batch_size) # update loss function tracking\n            preds.append(y_preds.to('cpu').numpy()) # save predictions\n            end = time.time() # get finish time\n\n            # ========== LOG INFO ==========\n            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n                print('EVAL: [{0}/{1}] '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.avg:.4f} '\n                      .format(step, len(valid_loader),\n                              loss=losses,\n                              remain=timeSince(start, float(step+1)/len(valid_loader))))\n            if config.WANDB:\n                wandb.log({f\"[fold_{fold}] val loss\": losses.val})\n                \n    prediction_dict[\"predictions\"] = np.concatenate(preds) # np.array() of shape (fold_size, target_cols)\n    prediction_dict[\"ids\"] = ids\n    return losses.avg, prediction_dict","metadata":{"papermill":{"duration":0.030759,"end_time":"2022-08-31T07:03:18.08056","exception":false,"start_time":"2022-08-31T07:03:18.049801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:46.443283Z","iopub.execute_input":"2023-11-01T04:27:46.443653Z","iopub.status.idle":"2023-11-01T04:27:46.469571Z","shell.execute_reply.started":"2023-11-01T04:27:46.443626Z","shell.execute_reply":"2023-11-01T04:27:46.468265Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train Loop</b><a class='anchor' id='train_loop'></a> [↑](#top) \n\n***","metadata":{"papermill":{"duration":0.0081,"end_time":"2022-08-31T07:03:18.100232","exception":false,"start_time":"2022-08-31T07:03:18.092132","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_loop(folds, fold):\n    \n    LOGGER.info(f\"========== Fold: {fold} training ==========\")\n\n    # ======== SPLIT ==========\n    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n\n    valid_labels = valid_folds['generated'].values\n\n    # ======== DATASETS ==========\n    train_dataset = CustomDataset(config, train_folds, tokenizer)\n    valid_dataset = CustomDataset(config, valid_folds, tokenizer)\n    \n    # ======== DATALOADERS ==========\n    train_loader = DataLoader(train_dataset,\n                              batch_size=config.BATCH_SIZE_TRAIN, # TODO: split into train and valid\n                              shuffle=True,\n                              pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=config.BATCH_SIZE_VALID,\n                              shuffle=False,\n                              pin_memory=True, drop_last=False)\n    \n    # ======== MODEL ==========\n    model = CustomModel(config, config_path=None, pretrained=True)\n    torch.save(model.config, paths.OUTPUT_DIR + '/config.pth')\n    model.to(device)\n\n    optimizer_parameters = get_optimizer_params(model,\n                                                encoder_lr=config.ENCODER_LR, \n                                                decoder_lr=config.DECODER_LR,\n                                                weight_decay=config.WEIGHT_DECAY)\n    optimizer = AdamW(optimizer_parameters,\n                      lr=config.ENCODER_LR,\n                      eps=config.EPS,\n                      betas=config.BETAS)\n    \n    scheduler = OneCycleLR(\n        optimizer,\n        max_lr=1e-5,\n        epochs=config.EPOCHS,\n        steps_per_epoch=len(train_loader),\n        pct_start=0.1,\n        anneal_strategy=\"cos\",\n        final_div_factor=100,\n    )\n\n    # ======= LOSS ==========\n    criterion = nn.BCEWithLogitsLoss()\n    \n    best_score = np.inf\n    # ====== ITERATE EPOCHS ========\n    for epoch in range(config.EPOCHS):\n\n        start_time = time.time()\n\n        # ======= TRAIN ==========\n        avg_loss = train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # ======= EVALUATION ==========\n        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, criterion, device)\n        predictions = prediction_dict[\"predictions\"]\n        # ======= SCORING ==========\n        score = get_score(valid_labels, sigmoid(predictions))\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n        \n        if config.WANDB:\n            wandb.log({f\"[fold_{fold}] epoch\": epoch+1, \n                       f\"[fold_{fold}] avg_train_loss\": avg_loss, \n                       f\"[fold_{fold}] avg_val_loss\": avg_val_loss,\n                       f\"[fold_{fold}] score\": score})\n            \n        if score < best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save(model.state_dict(),\n                        paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_fold_{fold}_best.pth\")\n            best_model_predictions = predictions\n\n    valid_folds[\"preds\"] = best_model_predictions\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return valid_folds","metadata":{"papermill":{"duration":0.033332,"end_time":"2022-08-31T07:03:18.141812","exception":false,"start_time":"2022-08-31T07:03:18.10848","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:51.565156Z","iopub.execute_input":"2023-11-01T04:27:51.565889Z","iopub.status.idle":"2023-11-01T04:27:51.580889Z","shell.execute_reply.started":"2023-11-01T04:27:51.565856Z","shell.execute_reply":"2023-11-01T04:27:51.579781Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#F1A424'>|</span> Train</b><a class='anchor' id='train'></a> [↑](#top) \n\n***","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    def get_result(oof_df):\n        labels = oof_df[\"generated\"].values\n        preds = oof_df[\"preds\"].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}')\n    \n    if config.TRAIN:\n        oof_df = pd.DataFrame()\n        for fold in range(config.FOLDS):\n            if fold == 0:\n                _oof_df = train_loop(train_df, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== Fold: {fold} result ==========\")\n                get_result(_oof_df)\n        oof_df = oof_df.reset_index(drop=True)\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        oof_df.to_csv(paths.OUTPUT_DIR + '/oof_df.csv', index=False)\n    if config.WANDB:\n        wandb.finish()","metadata":{"papermill":{"duration":11935.46951,"end_time":"2022-08-31T10:22:13.621316","exception":false,"start_time":"2022-08-31T07:03:18.151806","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-01T04:27:52.860847Z","iopub.execute_input":"2023-11-01T04:27:52.861219Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"========== Fold: 0 training ==========\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bef8607a30b4b00952b8822c653dc15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/94 [00:00<?, ?train_batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c814db3730e4171995231293718d6cd"}},"metadata":{}},{"name":"stdout","text":"Epoch: [1][0/94] Elapsed 0m 4s (remain 7m 32s) Loss: 0.8104 Grad: 499181.0312  LR: 0.00000043  \nEpoch: [1][20/94] Elapsed 1m 6s (remain 3m 50s) Loss: 0.7420 Grad: 197359.3750  LR: 0.00000882  \nEpoch: [1][40/94] Elapsed 2m 7s (remain 2m 45s) Loss: 0.6372 Grad: 77940.3438  LR: 0.00000993  \n","output_type":"stream"}]},{"cell_type":"code","source":"oof_df[\"preds\"] = oof_df[\"preds\"].apply(lambda x: sigmoid(x))\noof_df","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:14:53.376003Z","iopub.status.idle":"2023-11-01T04:14:53.376363Z","shell.execute_reply.started":"2023-11-01T04:14:53.376198Z","shell.execute_reply":"2023-11-01T04:14:53.376214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r output.zip /kaggle/working/output","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:14:53.377513Z","iopub.status.idle":"2023-11-01T04:14:53.377851Z","shell.execute_reply.started":"2023-11-01T04:14:53.377689Z","shell.execute_reply":"2023-11-01T04:14:53.377704Z"},"trusted":true},"execution_count":null,"outputs":[]}]}